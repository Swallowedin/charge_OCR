import streamlit as st
import os
import pandas as pd
import numpy as np
import pytesseract
import cv2
from PIL import Image
import json
import csv
from openai import OpenAI
import tempfile
import io
from pathlib import Path
import base64

# Titre et configuration de la page
st.set_page_config(
    page_title="Analyseur de Charges - Baux Commerciaux",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main {
        padding: 2rem;
    }
    .stTabs [data-baseweb="tab-panel"] {
        padding-top: 1rem;
    }
    .reportview-container .main .block-container {
        max-width: 1200px;
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    .stAlert {
        margin-top: 1rem;
    }
    .results-container {
        background-color: #f8f9fa;
        border-radius: 5px;
        padding: 1.5rem;
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

class ChargesAnalyzer:
    """
    Classe pour analyser les tableaux de charges des baux commerciaux 
    √† partir de diff√©rents formats (Excel, CSV, PDF) en utilisant l'OCR et GPT-4o-mini.
    """
    
    def __init__(self, api_key=None, ocr_api_key=None):
        """
        Initialise l'analyseur de charges.
        
        Args:
            api_key (str, optional): Cl√© API OpenAI.
            ocr_api_key (str, optional): Cl√© API OCR (si utilisation d'une API OCR externe).
        """
        self.api_key = api_key
        if not self.api_key:
            raise ValueError("Cl√© API OpenAI non fournie.")
            
        # Initialiser le client OpenAI
        self.client = OpenAI(api_key=self.api_key)
        
        # Stocker la cl√© API OCR si fournie
        self.ocr_api_key = ocr_api_key
        
        # Configuration de Tesseract OCR pour Streamlit Cloud
        # Dans Streamlit Cloud, nous devons utiliser pytesseract avec des configurations sp√©cifiques
        self.tesseract_config = r'--oem 3 --psm 6'
    
    def process_file(self, uploaded_file):
        """
        Traite un fichier t√©l√©charg√© par l'utilisateur.
        
        Args:
            uploaded_file (UploadedFile): Fichier t√©l√©charg√© via Streamlit.
            
        Returns:
            dict: R√©sultats de l'analyse structur√©s.
        """
        file_extension = Path(uploaded_file.name).suffix.lower()
        
        # Cr√©er un fichier temporaire
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as tmp_file:
            # √âcrire le contenu du fichier t√©l√©charg√© dans le fichier temporaire
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        try:
            if file_extension == '.pdf':
                result = self.analyze_pdf(tmp_path)
            elif file_extension in ['.xlsx', '.xls']:
                result = self.analyze_excel(tmp_path)
            elif file_extension == '.csv':
                result = self.analyze_csv(tmp_path)
            else:
                raise ValueError(f"Format de fichier non support√©: {file_extension}")
            
            # Supprimer le fichier temporaire
            os.unlink(tmp_path)
            
            return result
        except Exception as e:
            # Supprimer le fichier temporaire en cas d'erreur
            os.unlink(tmp_path)
            raise e
    
    def analyze_pdf(self, pdf_path):
        """
        Analyse un fichier PDF en utilisant l'OCR et GPT-4o-mini.
        
        Args:
            pdf_path (str): Chemin vers le fichier PDF.
            
        Returns:
            dict: R√©sultats de l'analyse.
        """
        st.info("Analyse du PDF en cours... Cette op√©ration peut prendre quelques instants.")
        progress_bar = st.progress(0)
        
        try:
            # Utiliser pdf2image pour convertir le PDF en images
            from pdf2image import convert_from_path
            
            # Sur Streamlit Cloud, nous devons sp√©cifier le chemin vers poppler
            try:
                images = convert_from_path(pdf_path)
            except Exception as e:
                st.error(f"Erreur lors de la conversion du PDF: {str(e)}")
                st.warning("Tentative d'installation de poppler...")
                
                # Afficher une information pour l'installation manuelle de poppler dans requirements.txt
                st.info("Assurez-vous que 'poppler-utils' est install√© sur votre serveur Streamlit Cloud. Ajoutez les d√©pendances dans requirements.txt")
                return {"error": "L'installation de poppler est requise pour traiter les PDFs."}
        
            extracted_text = ""
            total_pages = len(images)
            
            for i, image in enumerate(images):
                # Mettre √† jour la barre de progression
                progress_bar.progress((i + 0.5) / total_pages)
                
                # Pr√©traitement de l'image pour am√©liorer l'OCR
                img_np = np.array(image)
                
                # Conversion en niveaux de gris
                gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
                
                # Appliquer un seuillage pour am√©liorer la nettet√©
                _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
                
                # Effectuer l'OCR
                page_text = pytesseract.image_to_string(binary, config=self.tesseract_config, lang='fra')
                
                # Ajouter le texte extrait
                extracted_text += f"\n\n--- PAGE {i+1} ---\n\n{page_text}"
                
                # Mettre √† jour la barre de progression
                progress_bar.progress((i + 1) / total_pages)
        
            # Analyser le texte extrait avec GPT-4o-mini
            return self._analyze_with_gpt(extracted_text, source_type="PDF")
            
        except Exception as e:
            st.error(f"Erreur lors de l'analyse du PDF: {str(e)}")
            return {"error": str(e)}
    
    def analyze_excel(self, excel_path):
        """
        Analyse un fichier Excel.
        
        Args:
            excel_path (str): Chemin vers le fichier Excel.
            
        Returns:
            dict: R√©sultats de l'analyse.
        """
        st.info("Analyse du fichier Excel en cours...")
        
        try:
            # Lire toutes les feuilles du fichier Excel
            excel_data = {}
            xlsx = openpyxl.load_workbook(excel_path, data_only=True)
            
            for sheet_name in xlsx.sheetnames:
                sheet = xlsx[sheet_name]
                
                # Convertir la feuille en texte
                sheet_text = f"Feuille: {sheet_name}\n\n"
                
                for row in sheet.iter_rows(values_only=True):
                    row_values = [str(cell) if cell is not None else "" for cell in row]
                    sheet_text += " | ".join(row_values) + "\n"
                
                excel_data[sheet_name] = sheet_text
            
            # Concat√©ner toutes les feuilles en un seul texte
            combined_text = "\n\n".join([f"--- {sheet} ---\n{text}" for sheet, text in excel_data.items()])
            
            # Analyser avec GPT-4o-mini
            return self._analyze_with_gpt(combined_text, source_type="Excel")
            
        except Exception as e:
            st.error(f"Erreur lors de l'analyse du fichier Excel: {str(e)}")
            return {"error": str(e)}
    
    def analyze_csv(self, csv_path):
        """
        Analyse un fichier CSV.
        
        Args:
            csv_path (str): Chemin vers le fichier CSV.
            
        Returns:
            dict: R√©sultats de l'analyse.
        """
        st.info("Analyse du fichier CSV en cours...")
        
        try:
            # Essayer de d√©terminer le d√©limiteur
            with open(csv_path, 'r', encoding='utf-8', errors='replace') as file:
                sample = file.read(1024)
                sniffer = csv.Sniffer()
                delimiter = sniffer.sniff(sample).delimiter
            
            # Lire le CSV
            df = pd.read_csv(csv_path, delimiter=delimiter, encoding='utf-8', errors='replace')
            
            # Convertir en texte
            csv_text = df.to_string(index=False)
            
            # Analyser avec GPT-4o-mini
            return self._analyze_with_gpt(csv_text, source_type="CSV")
            
        except Exception as e:
            st.error(f"Erreur lors de l'analyse du fichier CSV: {str(e)}")
            return {"error": str(e)}
    
    def _analyze_with_gpt(self, text, source_type):
        """
        Utilise GPT-4o-mini pour analyser le texte extrait.
        
        Args:
            text (str): Texte √† analyser.
            source_type (str): Type de la source (PDF, Excel, CSV).
            
        Returns:
            dict: R√©sultats de l'analyse structur√©s.
        """
        st.info(f"Analyse du texte avec GPT-4o-mini en cours...")
        
        # Limiter la taille du texte si n√©cessaire
        if len(text) > 15000:
            st.warning(f"Le texte a √©t√© tronqu√© de {len(text)} √† 15000 caract√®res")
            text = text[:15000] + "...[tronqu√©]"
        
        # D√©finir le prompt pour GPT-4o-mini
        prompt = f"""
        Tu es un expert en analyse de tableaux de charges et redditions de charges pour des baux commerciaux.
        Voici un tableau de charges extrait d'un document {source_type}.
        
        {text}
        
        Analyse ce tableau de charges et extrait les informations suivantes au format JSON :
        1. Type de document (reddition de charges, appel de charges, budget pr√©visionnel)
        2. Ann√©e ou p√©riode concern√©e
        3. Montant total des charges
        4. R√©partition des charges par poste (nettoyage, s√©curit√©, maintenance, etc.)
        5. Quote-part du locataire si mentionn√©e
        6. Montant factur√© au locataire
        7. Montant des provisions d√©j√† vers√©es si applicable
        8. Solde (cr√©diteur ou d√©biteur)
        
        R√©ponds uniquement avec le JSON structur√© des r√©sultats.
        """
        
        try:
            # Appeler l'API OpenAI
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Tu es un assistant sp√©cialis√© dans l'analyse de documents financiers immobiliers."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1
            )
            
            # Extraire la r√©ponse
            analysis_text = response.choices[0].message.content
            
            # Nettoyer la r√©ponse pour extraire uniquement le JSON
            json_start = analysis_text.find('{')
            json_end = analysis_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_text = analysis_text[json_start:json_end]
                try:
                    # Analyser le JSON
                    analysis_result = json.loads(json_text)
                    st.success("Analyse r√©ussie!")
                    return analysis_result
                except json.JSONDecodeError as e:
                    st.error(f"Erreur de d√©codage JSON: {str(e)}")
                    return {"error": "Format de r√©ponse invalide", "raw_response": analysis_text}
            else:
                st.error("Pas de JSON trouv√© dans la r√©ponse")
                return {"error": "Pas de JSON trouv√© dans la r√©ponse", "raw_response": analysis_text}
            
        except Exception as e:
            st.error(f"Erreur lors de l'appel √† l'API OpenAI: {str(e)}")
            return {"error": str(e)}

def download_json(data):
    """G√©n√®re un lien de t√©l√©chargement pour les r√©sultats au format JSON."""
    json_str = json.dumps(data, indent=2, ensure_ascii=False)
    b64 = base64.b64encode(json_str.encode()).decode()
    href = f'<a href="data:application/json;base64,{b64}" download="resultats_analyse.json">T√©l√©charger les r√©sultats (JSON)</a>'
    return href

def display_results(results):
    """Affiche les r√©sultats de mani√®re structur√©e et claire."""
    if "error" in results:
        st.error(f"Erreur lors de l'analyse: {results['error']}")
        if "raw_response" in results:
            st.text_area("R√©ponse brute:", results["raw_response"], height=300)
        return
    
    st.markdown("## R√©sultats de l'analyse")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### Informations g√©n√©rales")
        st.info(f"**Type de document:** {results.get('Type de document', 'Non sp√©cifi√©')}")
        st.info(f"**P√©riode concern√©e:** {results.get('Ann√©e ou p√©riode concern√©e', 'Non sp√©cifi√©e')}")
        st.info(f"**Montant total des charges:** {results.get('Montant total des charges', 'Non sp√©cifi√©')}")
    
    with col2:
        st.markdown("### Informations financi√®res")
        st.info(f"**Quote-part du locataire:** {results.get('Quote-part du locataire', 'Non sp√©cifi√©e')}")
        st.info(f"**Montant factur√© au locataire:** {results.get('Montant factur√© au locataire', 'Non sp√©cifi√©')}")
        st.info(f"**Provisions d√©j√† vers√©es:** {results.get('Montant des provisions d√©j√† vers√©es', 'Non sp√©cifi√©')}")
        st.info(f"**Solde:** {results.get('Solde', 'Non sp√©cifi√©')}")
    
    # Afficher la r√©partition des charges si disponible
    if "R√©partition des charges par poste" in results and results["R√©partition des charges par poste"]:
        st.markdown("### R√©partition des charges par poste")
        
        # Convertir en dictionnaire si ce n'est pas d√©j√† le cas
        repartition = results["R√©partition des charges par poste"]
        if isinstance(repartition, str):
            try:
                repartition = json.loads(repartition)
            except:
                pass
        
        if isinstance(repartition, dict):
            # Cr√©er un DataFrame pour l'affichage
            df = pd.DataFrame({
                'Poste': list(repartition.keys()),
                'Montant': list(repartition.values())
            })
            
            # Afficher le tableau
            st.dataframe(df)
            
            # Cr√©er un graphique
            st.bar_chart(df.set_index('Poste'))
        else:
            st.write(repartition)
    
    # Bouton de t√©l√©chargement des r√©sultats
    st.markdown(download_json(results), unsafe_allow_html=True)
    
    # Afficher les r√©sultats JSON bruts dans un expander
    with st.expander("Voir les r√©sultats bruts (JSON)"):
        st.json(results)

def main():
    """Fonction principale de l'application Streamlit."""
    st.title("Analyseur de Tableaux de Charges pour Baux Commerciaux")
    st.markdown("""
    Cette application analyse vos tableaux de charges et redditions de charges pour des baux commerciaux.
    T√©l√©chargez un fichier PDF, Excel ou CSV et obtenez une analyse d√©taill√©e gr√¢ce √† l'OCR et √† l'IA.
    """)
    
    # Sidebar pour la configuration
    st.sidebar.title("Configuration")
    
    # R√©cup√©ration des cl√©s API depuis les secrets de Streamlit
    try:
        api_key = st.secrets["OPENAI_API_KEY"]
        st.sidebar.success("‚úÖ Cl√© API OpenAI charg√©e depuis les secrets")
    except Exception as e:
        st.sidebar.error("‚ùå Impossible de charger la cl√© API OpenAI depuis les secrets")
        api_key = st.sidebar.text_input("Cl√© API OpenAI (secours)", type="password")
        
    # R√©cup√©ration de la cl√© OCR API si disponible
    try:
        ocr_api_key = st.secrets["OCR_API_KEY"]
        st.sidebar.success("‚úÖ Cl√© API OCR charg√©e depuis les secrets")
    except Exception as e:
        ocr_api_key = None
    
    # Informations suppl√©mentaires dans la sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ## √Ä propos
    Cette application utilise:
    - OCR (Reconnaissance Optique de Caract√®res) pour extraire le texte des PDFs
    - GPT-4o-mini pour analyser le contenu
    - Streamlit pour l'interface utilisateur
    
    ## Formats support√©s
    - PDF
    - Excel (.xlsx, .xls)
    - CSV
    """)
    
    # Zone principale
    st.markdown("## T√©l√©chargement du fichier")
    uploaded_file = st.file_uploader("Choisissez un fichier √† analyser", type=["pdf", "xlsx", "xls", "csv"])
    
    if uploaded_file is not None:
        st.markdown("---")
        
        # Afficher des informations sur le fichier t√©l√©charg√©
        file_details = {
            "Nom du fichier": uploaded_file.name,
            "Type de fichier": uploaded_file.type,
            "Taille": f"{uploaded_file.size / 1024:.2f} KB"
        }
        
        st.markdown("### D√©tails du fichier")
        for key, value in file_details.items():
            st.info(f"**{key}:** {value}")
        
        # Bouton pour lancer l'analyse
        if st.button("Analyser le document"):
            if not api_key:
                st.error("Aucune cl√© API OpenAI disponible. V√©rifiez les secrets Streamlit ou entrez une cl√© manuellement.")
            else:
                try:
                    # Afficher un spinner pendant l'analyse
                    with st.spinner("Analyse en cours, veuillez patienter..."):
                        # Initialiser l'analyseur avec les deux cl√©s API
                        analyzer = ChargesAnalyzer(api_key=api_key, ocr_api_key=ocr_api_key)
                        
                        # Traiter le fichier
                        results = analyzer.process_file(uploaded_file)
                        
                        # Afficher les r√©sultats
                        display_results(results)
                except Exception as e:
                    st.error(f"Une erreur est survenue: {str(e)}")
                    st.exception(e)  # Affiche la trace compl√®te de l'erreur pour le d√©bogage

if __name__ == "__main__":
    # Afficher les informations sur les secrets disponibles (sans r√©v√©ler les valeurs)
    st.sidebar.markdown("### √âtat des secrets")
    secrets_status = {
        "OPENAI_API_KEY": "OPENAI_API_KEY" in st.secrets if hasattr(st, "secrets") else False,
        "OCR_API_KEY": "OCR_API_KEY" in st.secrets if hasattr(st, "secrets") else False
    }
    
    for secret_name, is_available in secrets_status.items():
        if is_available:
            st.sidebar.success(f"‚úÖ {secret_name} configur√©")
        else:
            st.sidebar.warning(f"‚ö†Ô∏è {secret_name} non configur√©")
    
    # Pour les erreurs li√©es √† l'OCR sur Streamlit Cloud
    try:
        import pytesseract
    except ImportError:
        st.error("La biblioth√®que pytesseract n'est pas install√©e. Ajoutez-la √† requirements.txt")
    
    try:
        # Tester si tesseract est install√©
        pytesseract.get_tesseract_version()
    except Exception as e:
        st.warning(f"Tesseract OCR n'est pas correctement configur√©: {str(e)}")
        st.info("Sur Streamlit Cloud, ajoutez 'tesseract-ocr' √† votre packages.txt")
    
    main()
